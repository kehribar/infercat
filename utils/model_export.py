# -----------------------------------------------------------------------------
# 
# 
# -----------------------------------------------------------------------------
import os
import re
import sys
import numpy as np

# ...
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import tensorflow as tf

# Taken from rnnoise project.
def getLayerActivationName(layer):
  return re.search('function (.*) at', str(layer.activation)).group(1).upper()

# ...
def putSeperator(fp):
  fp.write("// ")
  for i in range(0, 77): fp.write("-")
  fp.write("\r\n")

# ...
def putHeader(fp, modelname):
  putSeperator(fp)
  fp.write("// \r\n")
  fp.write("// This file is auto generated by model_export.py\r\n")
  putSeperator(fp)
  fp.write("#ifndef %s\r\n" % modelname.upper())
  fp.write("#define %s\r\n" % modelname.upper())
  fp.write("\r\n")
  fp.write("// ....\r\n");
  fp.write("#include <stdint.h>\r\n")
  fp.write("#include \"infercat.h\"\r\n");

# ...
def printDenseWeights(fp, name, data_type, data):

  # ...
  data_size = data.shape[0] * data.shape[1];

  # Transpose the weights and make it 1D
  data = data.transpose()
  data = np.reshape(data, data_size)

  # ...
  fp.write("\r\n");
  fp.write("// ...\r\n");
  fp.write("static const %s %s_weights[%d] = {\r\n  " % (data_type, name, data_size))
  for ind, x in enumerate(data):
    if(ind == (len(data) - 1)):
      fp.write("%12.9f\r\n" % x)
      fp.write("};\r\n");
    else:
      fp.write("%12.9f, " % x)
      if((ind % 5) == 4):
        fp.write("\r\n  ")

# ...
def printDenseBiases(fp, name, data_type, data):
  
  # Bias values are already 1D. Don't do anything extra
  data_size = len(data)
  
  # ...
  fp.write("\r\n");
  fp.write("// ...\r\n");
  fp.write("static const %s %s_biases[%d] = {\r\n  " % (data_type, name, data_size))
  for ind, x in enumerate(data):
    if(ind == (len(data) - 1)):
      fp.write("%12.9f\r\n" % x)
      fp.write("};\r\n");
    else:
      fp.write("%12.9f, " % x)
      if((ind % 5) == 4):
        fp.write("\r\n  ")

# ...
print("")
print("TENSORFLOW VERSION")
print("==================")
print(tf.version.VERSION)

# Load pre-trained model
model = tf.keras.models.load_model(sys.argv[1])

# Export file
fp = open(sys.argv[2], "w+")

# ...
modelname = os.path.split(sys.argv[2])[-1]
modelname = modelname.rsplit(".")[0]

# ...
putHeader(fp, modelname)

# ...
print("")
print("KERAS MODEL SUMMARY")
print("===================")
model.summary()

# ...
name_list = []
type_list = []
shape_list = []
activation_list = []

# ...
print("")
print("CUSTOM MODEL SUMMARY")
print("====================")
for ind, layer in enumerate(model.layers):
  weights = layer.get_weights()
  print("")
  print("LAYER", ind)
  print("-------")
  print("Name:", layer.name)

  # ...
  if(isinstance(layer, tf.keras.layers.Dense)):
   
    # ...
    activation = getLayerActivationName(layer)
    
    # ...
    print("Weights shape:", weights[0].shape)
    print("Bias shape:", weights[1].shape)
    print("Activation:", activation)
    print("Export supported: YES")

    # ...
    printDenseWeights(fp, layer.name, "float", weights[0])
    printDenseBiases(fp, layer.name, "float", weights[1])

    # ...
    name_list.append(layer.name)
    type_list.append("DENSE")
    shape_list.append(weights[0].shape)
    activation_list.append(activation)

  else:
    print("Export supported: NO")
    fp.close()
    sys.exit(0)

# ...
for x in range(0, len(name_list)):
  
  # ...
  name = name_list[x]
  type_ = type_list[x]
  shape = shape_list[x]
  activation = activation_list[x]

  # ...
  fp.write("\r\n")
  putSeperator(fp)
  fp.write("static float %s_output[%d];\r\n" % 
    (name, shape[1])
  )

  # ...
  fp.write("\r\n")
  fp.write("// ...\r\n")
  fp.write("const InfercatLayer %s = {\r\n" % name)
  fp.write("  .weight = %s_weights,\r\n" % name)  
  fp.write("  .bias = %s_biases,\r\n" % name)  
  fp.write("  .input_size = %d,\r\n" % shape[0])
  fp.write("  .output_size = %d,\r\n" % shape[1])
  fp.write("  .output_buffer = %s_output,\r\n" % name)
  fp.write("  .type = InfercatLayerType_%s,\r\n" % type_)
  fp.write("  .activation = InfercatLayerActivation_%s\r\n" % activation)
  fp.write("};\r\n")

# ...
fp.write("\r\n")
putSeperator(fp)
fp.write("#define %s_LAYERCOUNT %d\r\n" % 
  (modelname, len(name_list))
)

# ...
fp.write("\r\n")
fp.write("// ...\r\n")
fp.write("const InfercatLayer* %s[%d] = {\r\n  " % 
  (modelname, len(name_list))
)

# ...
for x in range(0, len(name_list)):
  if(x == (len(name_list) - 1)):
    fp.write("&%s\r\n" % name_list[x])
    fp.write("};\r\n")
  else:
    fp.write("&%s, " % name_list[x])

# ...
fp.write("\r\n")
fp.write("#endif\r\n")
fp.close()

# ...
print("")
print("Script exits.")
